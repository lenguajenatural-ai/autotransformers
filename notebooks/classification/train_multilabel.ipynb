{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lenguajenatural-ai/autotransformers/blob/main/notebooks/classification/train_multilabel.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel training\n",
    "\n",
    "This tutorial is very similar in many ways to the one on emotion classification, as both are classification task. So in this one there will be some parts which are not explained so much, as they are already explained on that previous tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the needed modules or, if you are running this notebook in Google colab, please uncomment the cell below and run it before importing, in order to install `autotransformers`.\n",
    "\n",
    "We import `DatasetConfig`, the class that configures how datasets are managed inside `AutoTrainer`. We also need `ModelConfig` to define the models to train, and `ResultsPlotter` to plot the experiment results.\n",
    "Additionally, we import the default hyperparameter space for base-sized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/lenguajenatural-ai/autotransformers.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotransformers import DatasetConfig, ModelConfig, AutoTrainer, ResultsPlotter\n",
    "from autotransformers.default_param_spaces import hp_space_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a preprocessing function, to end up with the correct format for the dataset. `AutoTrainer` expects multilabel datasets to be of the following form: one column for the text, and the rest of the columns for the labels. As our dataset is not originally in that format, we will pass a `pre_func` to `DatasetConfig` to preprocess it before tokenizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_parse_func(example):\n",
    "    label_cols = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"L\", \"M\", \"N\", \"Z\"]\n",
    "    new_example = {\"text\": example[\"abstractText\"]}\n",
    "    for col in label_cols:\n",
    "        new_example[f\"label_{col}\"] = example[col]\n",
    "    return new_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the fixed training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_train_args = {\n",
    "        \"evaluation_strategy\": \"steps\",\n",
    "        \"num_train_epochs\": 10,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"logging_strategy\": \"steps\",\n",
    "        \"eval_steps\": 1,\n",
    "        \"save_steps\": 1,\n",
    "        \"logging_steps\": 1,\n",
    "        \"save_strategy\": \"steps\",\n",
    "        \"save_total_limit\": 2,\n",
    "        \"seed\": 69,\n",
    "        \"fp16\": False,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"per_device_eval_batch_size\": 16,\n",
    "        \"max_steps\": 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default arguments for the dataset don't change with respect to classification tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args_dataset = {\n",
    "        \"seed\": 44,\n",
    "        \"direction_optimize\": \"maximize\",\n",
    "        \"metric_optimize\": \"eval_f1-score\",\n",
    "        \"retrain_at_end\": False,\n",
    "        \"fixed_training_args\": fixed_train_args\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define the configuration for pubmed dataset.\n",
    "\n",
    "For multilabel classification, we need to pass argument `is_multilabel=True`. `label_col` can be any of the labels in this case, so it is not important which one you use. Additionally, we must pass the `multilabel_label_names`, that is, the names of each of the labels in the multilabel task. As we need to preprocess the dataset before tokenizing text data, we set `pre_func=pre_parse_func`, using the function defined at the beginning of the tutorial. We also decide to remove unnecesary data fields after applying the `pre_func`, as they would cause an error in the tokenization step if kept in the dataset. For configuring the number of unique multilabel labels, use `config_num_labels=14`. Finally, as this dataset only has a `train` split, we need to perform a full split of the dataset with  `split=True` (that is, to create validation and test splits). In case we had test split but no validation split, we could have used `partial_split=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_config = default_args_dataset.copy()\n",
    "pubmed_config.update(\n",
    "    {\n",
    "        \"dataset_name\": \"pubmed\",\n",
    "        \"alias\": \"pubmed\",\n",
    "        \"task\": \"classification\",\n",
    "        \"is_multilabel\": True,\n",
    "        \"multilabel_label_names\": [f\"label_{col}\" for col in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"L\", \"M\", \"N\", \"Z\"]],\n",
    "        \"text_field\": \"text\",\n",
    "        \"label_col\": \"label_A\",\n",
    "        \"hf_load_kwargs\": {\"path\": \"owaiskha9654/PubMed_MultiLabel_Text_Classification_Dataset_MeSH\"},\n",
    "        \"pre_func\": pre_parse_func,\n",
    "        \"remove_fields_pre_func\": True,\n",
    "        \"config_num_labels\": 14,  # for multilabel we need to pass the number of labels for the config.\n",
    "        \"split\": True  # as the dataset only comes with train split, we need to split in train, val, test.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_config = DatasetConfig(**pubmed_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Configuration\n",
    "\n",
    "Now we can configure models, like in the classification tutorial.\n",
    "\n",
    "**Note that we are using Spanish models for an English task. As we are not actually trying to train realistic good performing models for this task this does not matter, as this notebook is for learning purposes solely. However, please make sure you choose models that fit your tasks when using `autotransformers` for real projects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertin_config = ModelConfig(\n",
    "        name=\"bertin-project/bertin-roberta-base-spanish\",\n",
    "        save_name=\"bertin\",\n",
    "        hp_space=hp_space_base,\n",
    "        n_trials=1,\n",
    ")\n",
    "beto_config = ModelConfig(\n",
    "        name=\"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "        save_name=\"beto\",\n",
    "        hp_space=hp_space_base,\n",
    "        n_trials=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AutoTrainer\n",
    "\n",
    "We can now create `AutoTrainer`. For that, we will use the model configs and the dataset config we have just created. We will additionally define a metrics dir, where metrics will be saved after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotrainer = AutoTrainer(\n",
    "        model_configs=[bertin_config, beto_config],\n",
    "        dataset_configs=[pubmed_config],\n",
    "        metrics_dir=\"pubmed_metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = autotrainer()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Results\n",
    "\n",
    "Once the models have trained, we might want to see a comparison of their performance. `ResultsPlotter` can be helpful in this respect, as we see in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = ResultsPlotter(\n",
    "        metrics_dir=autotrainer.metrics_dir,\n",
    "        model_names=[model_config.save_name for model_config in autotrainer.model_configs],\n",
    "        dataset_to_task_map={dataset_config.alias: dataset_config.task for dataset_config in autotrainer.dataset_configs},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plotter.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('largesum': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac692fd94dcfa608ba1aabbfbe7d5467f50ca857b57fe228a116df0c8b5b792"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
